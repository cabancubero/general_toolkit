{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the pandas library. I like to use the full names of my libraries in my code so it is easier to read\n",
    "\n",
    "import pandas as pandas\n",
    "\n",
    "#import the pandas.api -- We will use this in one of the regular expression cleans later on\n",
    "from pandas.api import types as pdtypes\n",
    "\n",
    "# Upload your file to a variable name of your choice\n",
    "\n",
    "your_file = pandas.read_csv('file_path')\n",
    "\n",
    "## This command allows me to see all of the columns in the dataframe when I call the .head() method\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "\n",
    "# Use the .head() method to see if your file loaded properly\n",
    "\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code block removes rows that don't meet a specific requirement.\n",
    "## In this example you will see that I am removing any row where the canvass status is NOT \"contact\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has nested instructions. First, it looks for the column \"canvas_status\"\n",
    "# Second, it searches every row where the status is NOT \"contact\"\n",
    "# Third, it pulls pulls the index of the row that did not have the \"contact\" status\n",
    "# Fourth, it uses the .drop() method to drop those rows by using the index of the row\n",
    "\n",
    "your_file = your_file.drop((your_file[your_file['canvas_status'] != 'contact'].index))\n",
    "\n",
    "\n",
    "#Let's see if it worked\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's break down how this worked! .drop() method in pandas expects row labels (index values) or column names as its argument, not a boolean mask.\n",
    "\n",
    "--> *df['column_name'] == 'specific_value'* creates a boolean mask where True indicates rows that meet the condition.\n",
    "--> *df[df['column_name'] == 'specific_value']* selects these rows from the DataFrame.\n",
    "--> *.index* retrieves the index labels of these selected rows.\n",
    "--> *.drop()* drops the rows whose index shows up after the boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns you need to drop\n",
    "# You will need to name every column you want to drop\n",
    "\n",
    "your_file = your_file.drop(columns=['column1',\n",
    "        'column2',\n",
    "        'column2'])\n",
    "\n",
    "#Let's see if it worked\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rename the columns to make our dataframe easier to read. We will use the .rename() method\n",
    "# The .rename() method requires a dictionary format for renaming\n",
    "# EXAMPLE: df = df.rename(columns={'old_name1': 'new_name1', 'old_name2': 'new_name2'})\n",
    "\n",
    "your_file = your_file.rename(columns={\n",
    "    'old_column_name1':'new_column_name1',\n",
    "    'old_column_name2':'new_column_name2',}\n",
    "    )\n",
    "\n",
    "#Let's see if it worked\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If I need to keep track of column names, for example\n",
    "    # If my column names are survey questions but I want to assign neater names to those columns\n",
    "# I will create a separate file that stores the original column name and the new column name. Like a key!\n",
    "# So I can reference the key in the future! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the dictionary from the .rename() method above and save it as a new variable\n",
    "\n",
    "your_file_dictionary = {\n",
    "    'question1':'shortened_column_name1',\n",
    "    'question2':'shortened_column_name2',\n",
    "}\n",
    "# Let's see if the dictionary saved properly\n",
    "print(your_file_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now turn the dictionary from before into a dataframe we can save to csv.\n",
    "\n",
    "your_file_dictionary_dataframe = pandas.DataFrame.from_dict(\n",
    "    your_file_dictionary,\n",
    "    orient='index')\n",
    "\n",
    "your_file_dictionary_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a file with the column names that you can use later as a reference if needed\n",
    "\n",
    "your_file_dictionary_dataframe.to_csv('new_file_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we want to iterate through the data in each column to make sure it's formatted properly.\n",
    "# In this example, we will only be removing special characters from number columns\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by creating a list of column names. \n",
    "## Assign the variable \"column_list\" a list of the column names you want to work on. \n",
    "## This variable will be used later!\n",
    "\n",
    "column_list = list(your_file.columns)\n",
    "\n",
    "#Make sure the columns are listed by printing the list\n",
    "print(column_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we will be using regex to clean up the data in these columns,\n",
    "# Make sure that each of the columns in the list are an object/string type.\n",
    "\n",
    "for column in column_list:\n",
    "    if column in your_file.columns:\n",
    "        your_file[column] = your_file[column].astype(str)\n",
    "\n",
    "#Use the .info() method to make sure it worked!\n",
    "your_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's create a function that will clean our data!\n",
    "\n",
    "# Create a function called \"clean_column\" that takes one argument \"column\" and\n",
    "    # first tests if the datatype is string\n",
    "        # and processes a str.replace() method on the argument \"column\"\n",
    "    # then returns the output as \"column\"\n",
    "    ## It will only do this on columns whose data type is \"string\" a.k.a. \"object\" in pandas\n",
    "\n",
    "def clean_column(column):\n",
    "    if pandas.api.types.is_string_dtype(column):\n",
    "        #Use any regex values you need to serve your project\n",
    "        return column.str.replace(r\"[\\[\\]'\\\"]\", \"\", regex=True)\n",
    "    else:\n",
    "        print(\"Column {column} is not string type, skipping\")\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pandas.api.types* is a submodule of pandas that provides a collection of data type-related functions and utilities. Here's a breakdown:\n",
    "\n",
    "**Namespace:** It's a way to organize related functionality within the pandas library.\n",
    "\n",
    "**Purpose:** This submodule contains functions for working with, checking, and manipulating data types in pandas.\n",
    "\n",
    "**Common uses**:\n",
    "-->Checking data types of Series or DataFrame columns\n",
    "-->Determining if a data type belongs to a certain category (e.g., numeric, string, etc.)\n",
    "-->Converting between different data types\n",
    "\n",
    "**Some common functions in this module:**\n",
    "\n",
    "-->*is_numeric_dtype()*: Checks if a dtype is numeric\n",
    "-->*is_datetime64_any_dtype()*: Checks if a dtype is any kind of datetime64 dtype\n",
    "-->*is_categorical_dtype()*: Checks if a dtype is of the Categorical type\n",
    "-->*is_string_dtype()*: Checks if a dtype is a string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an if statement that applies the \"clean_column()\"\" function to iterate over each column in \"column_list\"\n",
    "    #The first line tests If column is in the dataframe\n",
    "        #The second line runs the \"clean_column\" function on the dataframe using the label in the \"column_list\" list\n",
    "    #If it doesnt work, it prints a statement that says it didn't work \n",
    "\n",
    "for column in column_list:\n",
    "    if column in your_file.columns:\n",
    "        your_file[column] = clean_column(your_file[column])\n",
    "    else:\n",
    "        print(f\"Warning: Column '{column}' not found in the DataFrame\")\n",
    "\n",
    "#Let's see if it worked\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets reassign any columns with data that is numeric back to integer type since we are not working with floats.\n",
    "\n",
    "columns_to_convert_to_int = ['column1',\n",
    "    'column2',\n",
    "    'column3'\n",
    "    ]\n",
    "\n",
    "#Iterate over the items in the list\n",
    "for column in columns_to_convert_to_int:\n",
    "    your_file[column] = pandas.to_numeric(your_file[column], errors='coerce').astype('Int64')\n",
    "    \n",
    "#Let's make sure it worked\n",
    "your_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Let's make sure the previous code worked\n",
    "your_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now save your new file to a new path\n",
    "your_file.to_csv('new_file_path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
